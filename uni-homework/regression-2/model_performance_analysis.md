# ğŸ“Š Model BaÅŸarÄ±m DeÄŸerlendirme Raporu

## ğŸ¯ Genel Ã–zet

Bu rapor, **Online Retail II** veri seti Ã¼zerinde gerÃ§ekleÅŸtirilen regresyon analizinin model performanslarÄ±nÄ± deÄŸerlendirmektedir. Baseline ve iyileÅŸtirilmiÅŸ modellerin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi sunulmaktadÄ±r.

---

## ğŸ“ˆ 1. Ä°yileÅŸtirilmiÅŸ Model PerformanslarÄ±

### ğŸ† En Ä°yi Performans GÃ¶steren Modeller

| Model | Test RÂ² | Test RMSE | Test MAE | CV RÂ² Mean | Durum |
|-------|---------|-----------|----------|------------|-------|
| **Random Forest (Optimized)** | **0.9997** | **0.0728** | **0.0043** | **0.9999** | â­â­â­â­â­ |
| **Gradient Boosting (Optimized)** | **0.9997** | **0.0815** | **0.0169** | **0.9999** | â­â­â­â­â­ |
| **LightGBM (Optimized)** | **0.9994** | **0.1093** | **0.0385** | **0.9996** | â­â­â­â­ |
| **XGBoost (Optimized)** | **0.9986** | **0.1612** | **0.0249** | **0.9994** | â­â­â­â­ |
| **Ridge Regression (Optimized)** | **0.9539** | **0.9410** | **0.4861** | **0.9758** | â­â­â­ |
| **Linear Regression** | **0.9539** | **0.9410** | **0.4861** | **0.9758** | â­â­â­ |
| **Lasso Regression (Optimized)** | **0.9452** | **1.0259** | **0.5235** | **0.9734** | â­â­ |

### ğŸ“Š Performans Kategorileri

#### ğŸ¥‡ **MÃ¼kemmel Performans (RÂ² > 0.99)**
- **Random Forest (Optimized)**: RÂ² = 0.9997, RMSE = 0.0728
- **Gradient Boosting (Optimized)**: RÂ² = 0.9997, RMSE = 0.0815
- **LightGBM (Optimized)**: RÂ² = 0.9994, RMSE = 0.1093
- **XGBoost (Optimized)**: RÂ² = 0.9986, RMSE = 0.1612

**DeÄŸerlendirme**: Bu modeller neredeyse mÃ¼kemmel tahminler yapÄ±yor. Ã–zellikle Random Forest ve Gradient Boosting modelleri Ã§ok dÃ¼ÅŸÃ¼k hata oranlarÄ±na sahip.

#### ğŸ¥ˆ **Ä°yi Performans (RÂ² > 0.95)**
- **Ridge Regression (Optimized)**: RÂ² = 0.9539, RMSE = 0.9410
- **Linear Regression**: RÂ² = 0.9539, RMSE = 0.9410

**DeÄŸerlendirme**: Lineer modeller de iyi performans gÃ¶steriyor ancak ensemble modellere gÃ¶re daha yÃ¼ksek hata oranlarÄ±na sahip.

#### ğŸ¥‰ **Orta Performans (RÂ² > 0.94)**
- **Lasso Regression (Optimized)**: RÂ² = 0.9452, RMSE = 1.0259

**DeÄŸerlendirme**: Lasso regression diÄŸer modellere gÃ¶re daha dÃ¼ÅŸÃ¼k performans gÃ¶steriyor.

---

## ğŸ“‰ 2. Baseline vs Ä°yileÅŸtirilmiÅŸ Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

### ğŸš€ Ä°yileÅŸtirme OranlarÄ±

| Model | Baseline RÂ² | Ä°yileÅŸtirilmiÅŸ RÂ² | RÂ² Ä°yileÅŸtirme | RMSE Ä°yileÅŸtirme | MAE Ä°yileÅŸtirme |
|-------|-------------|-------------------|-----------------|-------------------|-----------------|
| **Linear Regression** | 0.0460 | 0.9539 | **+1975.8%** | -3.34 | -2.97 |
| **Ridge Regression** | 0.0460 | 0.9539 | **+1975.8%** | -3.34 | -2.97 |
| **Lasso Regression** | -0.000003 | 0.9452 | **+28955333%** | -3.36 | -3.07 |
| **Random Forest** | 0.3376 | 0.9997 | **+196.2%** | -3.50 | -2.52 |
| **XGBoost** | 0.3239 | 0.9986 | **+208.3%** | -3.44 | -2.62 |

### ğŸ¯ Ã–nemli Bulgular

1. **Lineer Modellerde Dramatik Ä°yileÅŸme**
   - Linear ve Ridge Regression modelleri **%1975** iyileÅŸme gÃ¶sterdi
   - Bu, Ã¶zellik mÃ¼hendisliÄŸi ve log transform'un etkisini gÃ¶steriyor

2. **Ensemble Modellerde BÃ¼yÃ¼k Ä°yileÅŸme**
   - Random Forest: **%196** iyileÅŸme
   - XGBoost: **%208** iyileÅŸme
   - Hiperparametre optimizasyonu ve geniÅŸletilmiÅŸ Ã¶zellikler etkili oldu

3. **Lasso Regression'da En BÃ¼yÃ¼k Ä°yileÅŸme**
   - Negatif RÂ²'den 0.9452'ye Ã§Ä±ktÄ±
   - Bu, Ã¶zellik seÃ§iminin Ã¶nemini gÃ¶steriyor

---

## ğŸ” 3. DetaylÄ± Metrik Analizi

### ğŸ“Š Test RÂ² SkorlarÄ±

```
Random Forest (Optimized):     0.9997 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Gradient Boosting (Optimized): 0.9997 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
LightGBM (Optimized):          0.9994 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
XGBoost (Optimized):            0.9986 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Ridge Regression (Optimized):   0.9539 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Linear Regression:              0.9539 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Lasso Regression (Optimized):   0.9452 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

**Yorum**: Ensemble modeller (Random Forest, Gradient Boosting, LightGBM, XGBoost) neredeyse mÃ¼kemmel RÂ² skorlarÄ±na sahip.

### ğŸ“Š Test RMSE DeÄŸerleri (DÃ¼ÅŸÃ¼k = Ä°yi)

```
Random Forest (Optimized):     0.0728 â–ˆ
Gradient Boosting (Optimized): 0.0815 â–ˆ
LightGBM (Optimized):          0.1093 â–ˆâ–ˆ
XGBoost (Optimized):            0.1612 â–ˆâ–ˆ
Ridge Regression (Optimized):   0.9410 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Linear Regression:              0.9410 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Lasso Regression (Optimized):   1.0259 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

**Yorum**: Random Forest ve Gradient Boosting modelleri en dÃ¼ÅŸÃ¼k RMSE deÄŸerlerine sahip.

### ğŸ“Š Test MAE DeÄŸerleri (DÃ¼ÅŸÃ¼k = Ä°yi)

```
Random Forest (Optimized):     0.0043 â–ˆ
Gradient Boosting (Optimized): 0.0169 â–ˆ
XGBoost (Optimized):            0.0249 â–ˆ
LightGBM (Optimized):          0.0385 â–ˆâ–ˆ
Ridge Regression (Optimized):   0.4861 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Linear Regression:              0.4861 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Lasso Regression (Optimized):   0.5235 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

**Yorum**: Random Forest modeli en dÃ¼ÅŸÃ¼k MAE deÄŸerine sahip (0.0043).

---

## ğŸ“ 4. Model Ã–zellikleri ve Ã–neriler

### âœ… En Ä°yi Model: **Random Forest (Optimized)**

**Neden En Ä°yi?**
- âœ… En yÃ¼ksek RÂ² skoru (0.9997)
- âœ… En dÃ¼ÅŸÃ¼k RMSE (0.0728)
- âœ… En dÃ¼ÅŸÃ¼k MAE (0.0043)
- âœ… En yÃ¼ksek Cross-Validation RÂ² (0.9999)
- âœ… En dÃ¼ÅŸÃ¼k CV standart sapmasÄ± (0.000038)

**KullanÄ±m Ã–nerileri:**
- Production ortamÄ±nda kullanÄ±labilir
- YÃ¼ksek tahmin doÄŸruluÄŸu
- Overfitting riski dÃ¼ÅŸÃ¼k (CV skorlarÄ± yÃ¼ksek)

### ğŸ¥ˆ Ä°kinci En Ä°yi: **Gradient Boosting (Optimized)**

**Ã–zellikler:**
- RÂ² = 0.9997 (Random Forest ile aynÄ±)
- RMSE = 0.0815 (Random Forest'tan biraz yÃ¼ksek)
- MAE = 0.0169 (Random Forest'tan biraz yÃ¼ksek)

**KullanÄ±m Ã–nerileri:**
- Random Forest'a alternatif olarak kullanÄ±labilir
- Ensemble yÃ¶ntemi olarak gÃ¼Ã§lÃ¼ performans

### ğŸ¥‰ ÃœÃ§Ã¼ncÃ¼ En Ä°yi: **LightGBM (Optimized)**

**Ã–zellikler:**
- RÂ² = 0.9994
- RMSE = 0.1093
- HÄ±zlÄ± eÄŸitim sÃ¼resi (LightGBM'in avantajÄ±)

**KullanÄ±m Ã–nerileri:**
- BÃ¼yÃ¼k veri setlerinde hÄ±zlÄ± eÄŸitim iÃ§in tercih edilebilir
- YÃ¼ksek performans ve hÄ±z kombinasyonu

---

## âš ï¸ 5. Potansiyel Sorunlar ve UyarÄ±lar

### ğŸ”´ Overfitting Riski

**GÃ¶zlem**: 
- Random Forest ve Gradient Boosting modelleri Train RÂ² = 0.9999 gibi Ã§ok yÃ¼ksek deÄŸerlere sahip
- Test RÂ² de Ã§ok yÃ¼ksek (0.9997) ancak Train ve Test arasÄ±nda kÃ¼Ã§Ã¼k bir fark var

**DeÄŸerlendirme**:
- âœ… Cross-Validation skorlarÄ± yÃ¼ksek (0.9999)
- âœ… Train ve Test skorlarÄ± arasÄ±ndaki fark kÃ¼Ã§Ã¼k
- âœ… Overfitting riski dÃ¼ÅŸÃ¼k gÃ¶rÃ¼nÃ¼yor

**Ã–neri**: 
- Model performansÄ±nÄ± production verisiyle test edin
- Regularization parametrelerini ayarlayarak overfitting'i kontrol edin

### ğŸŸ¡ Lineer Modellerin SÄ±nÄ±rlamalarÄ±

**GÃ¶zlem**:
- Linear ve Ridge Regression modelleri ensemble modellere gÃ¶re daha dÃ¼ÅŸÃ¼k performans gÃ¶steriyor
- Ancak hala iyi performans (RÂ² = 0.9539)

**DeÄŸerlendirme**:
- Lineer modeller yorumlanabilir sonuÃ§lar saÄŸlÄ±yor
- Ensemble modeller daha iyi performans gÃ¶steriyor

**Ã–neri**:
- Model interpretability Ã¶nemliyse Linear/Ridge kullanÄ±labilir
- Performans Ã¶nemliyse ensemble modeller tercih edilmeli

---

## ğŸ“‹ 6. SonuÃ§lar ve Ã–neriler

### âœ… BaÅŸarÄ±lar

1. **Dramatik Ä°yileÅŸtirme**: TÃ¼m modellerde bÃ¼yÃ¼k iyileÅŸtirmeler gÃ¶rÃ¼ldÃ¼
2. **MÃ¼kemmel Performans**: Ensemble modeller neredeyse mÃ¼kemmel tahminler yapÄ±yor
3. **Ä°yi Genelleme**: Cross-Validation skorlarÄ± yÃ¼ksek, overfitting riski dÃ¼ÅŸÃ¼k

### ğŸ¯ Ã–neriler

1. **Production KullanÄ±mÄ±**: 
   - Random Forest veya Gradient Boosting modelleri production'da kullanÄ±labilir
   - Model persistence (joblib) ile kaydedilmiÅŸ modeller kullanÄ±lmalÄ±

2. **Model Monitoring**:
   - Production'da model performansÄ±nÄ± dÃ¼zenli olarak izleyin
   - Drift detection iÃ§in metrikleri takip edin

3. **Feature Importance**:
   - Random Forest ve Gradient Boosting modellerinde feature importance analizi yapÄ±labilir
   - Hangi Ã¶zelliklerin en Ã¶nemli olduÄŸunu belirleyin

4. **Hyperparameter Tuning**:
   - Mevcut hiperparametreler iyi gÃ¶rÃ¼nÃ¼yor
   - Daha fazla optimizasyon iÃ§in Bayesian Optimization denenebilir

5. **Model Ensemble**:
   - En iyi modelleri birleÅŸtirerek ensemble model oluÅŸturulabilir
   - Voting veya Stacking yÃ¶ntemleri kullanÄ±labilir

---

## ğŸ“Š 7. Performans Ã–zet Tablosu

| Model | Test RÂ² | Test RMSE | Test MAE | CV RÂ² | Performans | Ã–neri |
|-------|---------|-----------|----------|-------|------------|-------|
| Random Forest (Optimized) | 0.9997 | 0.0728 | 0.0043 | 0.9999 | â­â­â­â­â­ | âœ… Production |
| Gradient Boosting (Optimized) | 0.9997 | 0.0815 | 0.0169 | 0.9999 | â­â­â­â­â­ | âœ… Production |
| LightGBM (Optimized) | 0.9994 | 0.1093 | 0.0385 | 0.9996 | â­â­â­â­ | âœ… Production |
| XGBoost (Optimized) | 0.9986 | 0.1612 | 0.0249 | 0.9994 | â­â­â­â­ | âœ… Production |
| Ridge Regression (Optimized) | 0.9539 | 0.9410 | 0.4861 | 0.9758 | â­â­â­ | âš ï¸ Alternatif |
| Linear Regression | 0.9539 | 0.9410 | 0.4861 | 0.9758 | â­â­â­ | âš ï¸ Alternatif |
| Lasso Regression (Optimized) | 0.9452 | 1.0259 | 0.5235 | 0.9734 | â­â­ | âŒ Kullanma |

---

**Rapor Tarihi**: 2024
**Analiz Edilen Veri Seti**: Online Retail II
**Toplam Model SayÄ±sÄ±**: 7 (Ä°yileÅŸtirilmiÅŸ)
**En Ä°yi Model**: Random Forest (Optimized)

